{"id": "2510.25269", "categories": ["cs.PF"], "pdf": "https://arxiv.org/pdf/2510.25269", "abs": "https://arxiv.org/abs/2510.25269", "authors": ["Benjamin A. Antunes"], "title": "The influence of the random numbers quality on the results in stochastic simulations and machine learning", "comment": null, "summary": "Pseudorandom number generators (PRNGs) are ubiquitous in stochastic\nsimulations and machine learning (ML), where they drive sampling, parameter\ninitialization, regularization, and data shuffling. While widely used, the\npotential impact of PRNG statistical quality on computational results remains\nunderexplored. In this study, we investigate whether differences in PRNG\nquality, as measured by standard statistical test suites, can influence\noutcomes in representative stochastic applications. Seven PRNGs were evaluated,\nranging from low-quality linear congruential generators (LCGs) with known\nstatistical deficiencies to high-quality generators such as Mersenne Twister,\nPCG, and Philox. We applied these PRNGs to four distinct tasks: an\nepidemiological agent-based model (ABM), two independent from-scratch MNIST\nclassification implementations (Python/NumPy and C++), and a reinforcement\nlearning (RL) CartPole environment. Each experiment was repeated 30 times per\ngenerator using fixed seeds to ensure reproducibility, and outputs were\ncompared using appropriate statistical analyses. Results show that very poor\nstatistical quality, as in the ''bad'' LCG failing 125 TestU01 Crush tests,\nproduces significant deviations in ABM epidemic dynamics, reduces MNIST\nclassification accuracy, and severely degrades RL performance. In contrast,\nmid-and good-quality LCGs-despite failing a limited number of Crush or BigCrush\ntests-performed comparably to top-tier PRNGs in most tasks, with the RL\nexperiment being the primary exception where performance scaled with\nstatistical quality. Our findings indicate that, once a generator meets a\nsufficient statistical robustness threshold, its family or design has\nnegligible impact on outcomes for most workloads, allowing selection to be\nguided by performance and implementation considerations. However, the use of\nlow-quality PRNGs in sensitive stochastic computations can introduce\nsubstantial and systematic errors.", "AI": {"tldr": "Study investigates how PRNG statistical quality affects computational results in stochastic applications, finding that very poor quality PRNGs cause significant deviations while mid-to-good quality PRNGs perform comparably to top-tier ones once a statistical robustness threshold is met.", "motivation": "To explore the underinvestigated impact of PRNG statistical quality on computational results in stochastic simulations and machine learning applications, where PRNGs are widely used but their quality effects remain unclear.", "method": "Evaluated 7 PRNGs ranging from low-quality LCGs to high-quality generators (Mersenne Twister, PCG, Philox) across four tasks: epidemiological ABM, two MNIST classification implementations, and RL CartPole environment. Each experiment repeated 30 times per generator with fixed seeds.", "result": "Very poor quality PRNGs (bad LCG failing 125 TestU01 Crush tests) produced significant deviations in epidemic dynamics, reduced MNIST accuracy, and severely degraded RL performance. Mid-to-good quality PRNGs performed comparably to top-tier ones in most tasks, except RL where performance scaled with statistical quality.", "conclusion": "Once a generator meets sufficient statistical robustness threshold, its family/design has negligible impact on outcomes for most workloads, allowing selection based on performance and implementation. However, low-quality PRNGs in sensitive stochastic computations can introduce substantial systematic errors."}}
{"id": "2510.25040", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2510.25040", "abs": "https://arxiv.org/abs/2510.25040", "authors": ["Madhav Vadlamani", "Dyutimoy Chakraborty", "Jianwei Jia", "Halid Mulaosmanovic", "Stefan Duenkel", "Sven Beyer", "Suman Datta", "Shimeng Yu"], "title": "Cryogenic Characterization of Ferroelectric Non-volatile Capacitors", "comment": null, "summary": "Ferroelectric-based capacitive crossbar arrays have been proposed for\nenergy-efficient in-memory computing in the charge domain. They combat the\nchallenges like sneak paths and high static power faced by resistive crossbar\narrays but are susceptible to thermal noise limiting the effective number of\nbits (ENOB) for the weighted sum. A direct way to reduce this thermal noise is\nby lowering the temperature as thermal noise is proportional to temperature. In\nthis work, we first characterize the non-volatile capacitors (nvCaps) on a\nfoundry 28 nm platform at cryogenic temperatures to evaluate the memory window,\nON state retention as a function of temperature down to 77K, and then use the\ncalibrated device models to simulate the capacitive crossbar arrays in SPICE at\nlower temperatures to demonstrate higher ENOB (~5 bits) for 128x128\nmultiple-and-accumulate (MAC) operations.", "AI": {"tldr": "This paper demonstrates that operating ferroelectric capacitive crossbar arrays at cryogenic temperatures (down to 77K) significantly reduces thermal noise, enabling higher effective number of bits (~5 bits) for 128x128 MAC operations in in-memory computing systems.", "motivation": "Ferroelectric capacitive crossbar arrays offer energy-efficient in-memory computing but suffer from thermal noise limiting the effective number of bits for weighted sum operations. Lowering temperature directly reduces thermal noise since it's proportional to temperature.", "method": "Characterized non-volatile capacitors on a foundry 28 nm platform at cryogenic temperatures to evaluate memory window and ON state retention down to 77K, then used calibrated device models to simulate capacitive crossbar arrays in SPICE at lower temperatures.", "result": "Demonstrated higher effective number of bits (~5 bits) for 128x128 multiple-and-accumulate operations when operating at cryogenic temperatures compared to room temperature operation.", "conclusion": "Cryogenic operation of ferroelectric capacitive crossbar arrays is an effective approach to mitigate thermal noise limitations and achieve higher computational precision for in-memory computing applications."}}
{"id": "2510.24943", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.24943", "abs": "https://arxiv.org/abs/2510.24943", "authors": ["Alfonso Ladino-Rincon", "Stephen W. Nesbitt"], "title": "Radar DataTree: A FAIR and Cloud-Native Framework for Scalable Weather Radar Archives", "comment": "8 pages, 3 figures", "summary": "We introduce Radar DataTree, the first dataset-level framework that extends\nthe WMO FM-301 standard from individual radar volume scans to time-resolved,\nanalysis-ready archives. Weather radar data are among the most scientifically\nvaluable yet structurally underutilized Earth observation datasets. Despite\nwidespread public availability, radar archives remain fragmented,\nvendor-specific, and poorly aligned with FAIR (Findable, Accessible,\nInteroperable, Reusable) principles, hindering large-scale research,\nreproducibility, and cloud-native computation. Radar DataTree addresses these\nlimitations with a scalable, open-source architecture that transforms\noperational radar archives into FAIR-compliant, cloud-optimized datasets. Built\non the FM-301/CfRadial 2.1 standard and implemented using xarray DataTree,\nRadar DataTree organizes radar volume scans as hierarchical, metadata-rich\nstructures and serializes them to Zarr for scalable analysis. Coupled with\nIcechunk for ACID-compliant storage and versioning, this architecture enables\nefficient, parallel computation across thousands of radar scans with minimal\npreprocessing. We demonstrate significant performance gains in case studies\nincluding Quasi-Vertical Profile (QVP) and precipitation accumulation\nworkflows, and release all tools and datasets openly via the Raw2Zarr\nrepository. This work contributes a reproducible and extensible foundation for\nradar data stewardship, high-performance geoscience, and AI-ready weather\ninfrastructure.", "AI": {"tldr": "Radar DataTree is the first dataset-level framework that transforms operational weather radar archives into FAIR-compliant, cloud-optimized datasets using hierarchical structures and Zarr serialization, enabling scalable analysis with significant performance improvements.", "motivation": "Weather radar data are scientifically valuable but underutilized due to fragmented archives, vendor-specific formats, and poor alignment with FAIR principles, which hinders large-scale research, reproducibility, and cloud-native computation.", "method": "Built on FM-301/CfRadial 2.1 standard and implemented using xarray DataTree, Radar DataTree organizes radar volume scans as hierarchical, metadata-rich structures and serializes them to Zarr. It uses Icechunk for ACID-compliant storage and versioning to enable efficient parallel computation across thousands of scans.", "result": "The framework demonstrates significant performance gains in case studies including Quasi-Vertical Profile (QVP) and precipitation accumulation workflows. All tools and datasets are released openly via the Raw2Zarr repository.", "conclusion": "This work provides a reproducible and extensible foundation for radar data stewardship, high-performance geoscience, and AI-ready weather infrastructure, addressing current limitations in radar data utilization."}}
{"id": "2510.25170", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25170", "abs": "https://arxiv.org/abs/2510.25170", "authors": ["Kewei Wang", "Claire Songhyun Lee", "Sunwoo Lee", "Vishu Gupta", "Jan Balewski", "Alex Sim", "Peter Nugent", "Ankit Agrawal", "Alok Choudhary", "Kesheng Wu", "Wei-keng Liao"], "title": "Multi-Resolution Model Fusion for Accelerating the Convolutional Neural Network Training", "comment": null, "summary": "Neural networks are rapidly gaining popularity in scientific research, but\ntraining the models is often very time-consuming. Particularly when the\ntraining data samples are large high-dimensional arrays, efficient training\nmethodologies that can reduce the computational costs are crucial. To reduce\nthe training cost, we propose a Multi-Resolution Model Fusion (MRMF) method\nthat combines models trained on reduced-resolution data and then refined with\ndata in the original resolution. We demonstrate that these reduced-resolution\nmodels and datasets could be generated quickly. More importantly, the proposed\napproach reduces the training time by speeding up the model convergence in each\nfusion stage before switching to the final stage of finetuning with data in its\noriginal resolution. This strategy ensures the final model retains\nhigh-resolution insights while benefiting from the computational efficiency of\nlower-resolution training. Our experiment results demonstrate that the\nmulti-resolution model fusion method can significantly reduce end-to-end\ntraining time while maintaining the same model accuracy. Evaluated using two\nreal-world scientific applications, CosmoFlow and Neuron Inverter, the proposed\nmethod improves the training time by up to 47% and 44%, respectively, as\ncompared to the original resolution training, while the model accuracy is not\naffected.", "AI": {"tldr": "Proposes Multi-Resolution Model Fusion (MRMF) method to reduce neural network training time by combining models trained on reduced-resolution data and refining with original resolution data, achieving up to 47% training time reduction without accuracy loss.", "motivation": "Neural network training is time-consuming, especially with large high-dimensional data. Need efficient methodologies to reduce computational costs while maintaining model performance.", "method": "Multi-Resolution Model Fusion (MRMF) that trains models on reduced-resolution data first, then fuses and refines them with original resolution data. Uses progressive convergence strategy across resolution stages.", "result": "Reduces training time by up to 47% for CosmoFlow and 44% for Neuron Inverter applications compared to original resolution training, while maintaining same model accuracy.", "conclusion": "The multi-resolution model fusion approach effectively reduces neural network training time significantly without compromising model accuracy, making it valuable for scientific applications with large datasets."}}
{"id": "2510.25258", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25258", "abs": "https://arxiv.org/abs/2510.25258", "authors": ["Xinru Tang", "Jingxiang Hou", "Dingcheng Jiang", "Taiquan Wei", "Jiaxin Liu", "Jinyi Deng", "Huizheng Wang", "Qize Yang", "Haoran Shang", "Chao Li", "Yang Hu", "Shouyi Yin"], "title": "MoEntwine: Unleashing the Potential of Wafer-scale Chips for Large-scale Expert Parallel Inference", "comment": null, "summary": "As large language models (LLMs) continue to scale up, mixture-of-experts\n(MoE) has become a common technology in SOTA models. MoE models rely on expert\nparallelism (EP) to alleviate memory bottleneck, which introduces all-to-all\ncommunication to dispatch and combine tokens across devices. However, in\nwidely-adopted GPU clusters, high-overhead cross-node communication makes\nall-to-all expensive, hindering the adoption of EP. Recently, wafer-scale chips\n(WSCs) have emerged as a platform integrating numerous devices on a wafer-sized\ninterposer. WSCs provide a unified high-performance network connecting all\ndevices, presenting a promising potential for hosting MoE models. Yet, their\nnetwork is restricted to a mesh topology, causing imbalanced communication\npressure and performance loss. Moreover, the lack of on-wafer disk leads to\nhigh-overhead expert migration on the critical path.\n  To fully unleash this potential, we first propose Entwined Ring Mapping\n(ER-Mapping), which co-designs the mapping of attention and MoE layers to\nbalance communication pressure and achieve better performance. We find that\nunder ER-Mapping, the distribution of cold and hot links in the attention and\nMoE layers is complementary. Therefore, to hide the migration overhead, we\npropose the Non-invasive Balancer (NI-Balancer), which splits a complete expert\nmigration into multiple steps and alternately utilizes the cold links of both\nlayers. Evaluation shows ER-Mapping achieves communication reduction up to 62%.\nNI-Balancer further delivers 54% and 22% improvements in MoE computation and\ncommunication, respectively. Compared with the SOTA NVL72 supernode, the WSC\nplatform delivers an average 39% higher per-device MoE performance owing to its\nscalability to larger EP.", "AI": {"tldr": "This paper proposes ER-Mapping and NI-Balancer to optimize Mixture-of-Experts (MoE) models on wafer-scale chips by balancing communication pressure and hiding expert migration overhead, achieving significant performance improvements over traditional GPU clusters.", "motivation": "MoE models face communication bottlenecks in GPU clusters due to expensive cross-node all-to-all communication. Wafer-scale chips (WSCs) offer high-performance networking but suffer from imbalanced communication pressure in mesh topology and high-overhead expert migration due to lack of on-wafer disk.", "method": "Proposes Entwined Ring Mapping (ER-Mapping) to co-design attention and MoE layer mappings for balanced communication pressure, and Non-invasive Balancer (NI-Balancer) to split expert migration into multiple steps using cold links of both layers to hide migration overhead.", "result": "ER-Mapping achieves up to 62% communication reduction. NI-Balancer delivers 54% improvement in MoE computation and 22% in communication. WSC platform provides 39% higher per-device MoE performance compared to SOTA NVL72 supernode.", "conclusion": "The proposed techniques effectively address communication bottlenecks in MoE models on wafer-scale chips, demonstrating significant performance advantages over traditional GPU clusters through balanced communication mapping and optimized migration strategies."}}
{"id": "2510.25277", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25277", "abs": "https://arxiv.org/abs/2510.25277", "authors": ["Simon S\u00fcwer", "Mai Khanh Mai", "Christoph Klein", "Nicola G\u00f6tzenberger", "Denis Dali\u0107", "Andreas Maier", "Jan Baumbach"], "title": "A Privacy-Preserving Ecosystem for Developing Machine Learning Algorithms Using Patient Data: Insights from the TUM.ai Makeathon", "comment": null, "summary": "The integration of clinical data offers significant potential for the\ndevelopment of personalized medicine. However, its use is severely restricted\nby the General Data Protection Regulation (GDPR), especially for small cohorts\nwith rare diseases. High-quality, structured data is essential for the\ndevelopment of predictive medical AI. In this case study, we propose a novel,\nmulti-stage approach to secure AI training: (1) The model is designed on a\nsimulated clinical knowledge graph (cKG). This graph is used exclusively to\nrepresent the structural characteristics of the real cKG without revealing any\nsensitive content. (2) The model is then integrated into the FeatureCloud (FC)\nfederated learning framework, where it is prepared in a single-client\nconfiguration within a protected execution environment. (3) Training then takes\nplace within the hospital environment on the real cKG, either under the direct\nsupervision of hospital staff or via a fully automated pipeline controlled by\nthe hospital. (4) Finally, verified evaluation scripts are executed, which only\nreturn aggregated performance metrics. This enables immediate performance\nfeedback without sensitive patient data or individual predictions, leaving the\nclinic. A fundamental element of this approach involves the incorporation of a\ncKG, which serves to organize multi-omics and patient data within the context\nof real-world hospital environments. This approach was successfully validated\nduring the TUM.ai Makeathon 2024 (TUMaiM24) challenge set by the Dr. von Hauner\nChildren's Hospital (HCH-LMU): 50 students developed models for patient\nclassification and diagnosis without access to real data. Deploying secure\nalgorithms via federated frameworks, such as the FC framework, could be a\npractical way of achieving privacy-preserving AI in healthcare.", "AI": {"tldr": "A multi-stage approach for secure AI training in healthcare that uses simulated clinical knowledge graphs and federated learning to enable model development without accessing sensitive patient data, validated in a student challenge.", "motivation": "To address GDPR restrictions that limit clinical data use for personalized medicine, especially for rare diseases with small cohorts, while maintaining data privacy and enabling predictive AI development.", "method": "Four-stage approach: (1) Model design on simulated clinical knowledge graphs, (2) Integration into FeatureCloud federated learning framework in protected environment, (3) Training on real data within hospital environment under hospital supervision, (4) Execution of verified evaluation scripts returning only aggregated performance metrics.", "result": "Successfully validated during TUM.ai Makeathon 2024 where 50 students developed patient classification and diagnosis models without access to real data, demonstrating practical implementation of privacy-preserving AI in healthcare.", "conclusion": "Deploying secure algorithms via federated frameworks like FeatureCloud provides a practical solution for achieving privacy-preserving AI in healthcare while complying with GDPR regulations."}}
{"id": "2510.25362", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25362", "abs": "https://arxiv.org/abs/2510.25362", "authors": ["Georgios L. Stavrinides", "Helen D. Karatza"], "title": "Scheduling Data-Intensive Workloads in Large-Scale Distributed Systems: Trends and Challenges", "comment": "This version of the manuscript has been accepted for publication in\n  Modeling and Simulation in HPC and Cloud Systems, ser. Studies in Big Data,\n  after peer review (Author Accepted Manuscript). It is not the final published\n  version (Version of Record) and does not reflect any post-acceptance\n  improvements. The Version of Record is available online at\n  https://doi.org/10.1007/978-3-319-73767-6_2", "summary": "With the explosive growth of big data, workloads tend to get more complex and\ncomputationally demanding. Such applications are processed on distributed\ninterconnected resources that are becoming larger in scale and computational\ncapacity. Data-intensive applications may have different degrees of parallelism\nand must effectively exploit data locality. Furthermore, they may impose\nseveral Quality of Service requirements, such as time constraints and\nresilience against failures, as well as other objectives, like energy\nefficiency. These features of the workloads, as well as the inherent\ncharacteristics of the computing resources required to process them, present\nmajor challenges that require the employment of effective scheduling\ntechniques. In this chapter, a classification of data-intensive workloads is\nproposed and an overview of the most commonly used approaches for their\nscheduling in large-scale distributed systems is given. We present novel\nstrategies that have been proposed in the literature and shed light on open\nchallenges and future directions.", "AI": {"tldr": "This chapter provides a classification of data-intensive workloads and surveys scheduling approaches for large-scale distributed systems, addressing challenges like parallelism, data locality, QoS requirements, and energy efficiency.", "motivation": "The explosive growth of big data has led to more complex and computationally demanding workloads that require effective scheduling techniques to handle challenges like varying parallelism, data locality, QoS requirements, and energy efficiency in large-scale distributed systems.", "method": "The authors propose a classification of data-intensive workloads and provide an overview of commonly used scheduling approaches, presenting novel strategies from the literature.", "result": "The chapter offers a comprehensive classification framework and survey of scheduling techniques for data-intensive applications in distributed systems.", "conclusion": "The work sheds light on open challenges and future directions in scheduling for data-intensive workloads in large-scale distributed computing environments."}}
{"id": "2510.25451", "categories": ["cs.DC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2510.25451", "abs": "https://arxiv.org/abs/2510.25451", "authors": ["St\u00e9phane Devismes", "Yoann Dieudonn\u00e9", "Arnaud Labourel"], "title": "Can Like Attract Like? A Study of Homonymous Gathering in Networks", "comment": null, "summary": "A team of mobile agents, starting from distinct nodes of a network, have to\nmeet at the same node and declare that they all met. Agents execute the same\nalgorithm, which they start when activated by an adversary or by an agent\nentering their initial node. When activated, agents traverse edges of the\nnetwork in synchronous rounds. Their perception and communication are strictly\nlocal. This task, known as gathering, is a central problem in distributed\nmobile systems. Most prior work focuses on minimizing its time complexity,\ni.e., the worst-case number of rounds between the start of the earliest agent\nand the task completion. To break possible symmetries, deterministic solutions\ntypically assume that agents have pairwise distinct IDs, called labels, known\nonly to themselves. But must all labels be pairwise distinct to guarantee\ndeterministic gathering?\n  We address this question by considering agents that may share the same label.\nA team L is said to be gatherable if, for every initial setting of L, there is\nan algorithm that solves gathering. Our contribution is threefold. (1) We give\na full characterization of the gatherable teams. (2) We design an algorithm\nthat gathers all of them in poly$(n,\\log\\lambda)$ time, where $n$ (resp.\n$\\lambda$) is the graph order (resp. the smallest label in L). This algorithm\nrequires the agents to initially share only $O(\\log \\log \\log \\mu)$ bits of\ncommon knowledge, where $\\mu$ is the largest label multiplicity in L. (3) We\nshow this dependency is almost optimal to get a poly$(n,\\log\\lambda)$-time\ncomplexity.\n  As a by-product, we get the first deterministic poly$(n,\\log\\lambda)$-time\nalgorithm requiring no common knowledge to gather any team when all labels are\ndistinct. Known to be achievable for two-agent teams, extending this to any\nteam size faced a major challenge: termination detection. Our techniques to\naddress it may be of independent interest.", "AI": {"tldr": "This paper studies the gathering problem for mobile agents with possibly non-unique labels, characterizing which teams are gatherable and providing efficient algorithms with minimal common knowledge requirements.", "motivation": "To determine whether all agent labels must be pairwise distinct for deterministic gathering, and to understand the minimal common knowledge needed for efficient gathering algorithms.", "method": "Characterizes gatherable teams, designs poly(n,log\u03bb)-time gathering algorithm requiring only O(log log log \u03bc) bits of common knowledge, and proves near-optimality of this dependency.", "result": "Full characterization of gatherable teams, efficient gathering algorithm with minimal common knowledge, and first deterministic poly(n,log\u03bb)-time algorithm for distinct labels without common knowledge.", "conclusion": "Not all labels need to be distinct for deterministic gathering, and minimal common knowledge (O(log log log \u03bc) bits) suffices for efficient gathering, with near-optimal dependency."}}
{"id": "2510.25757", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2510.25757", "abs": "https://arxiv.org/abs/2510.25757", "authors": ["Jonas Spenger", "Kolya Krafeld", "Ruben van Gemeren", "Philipp Haller", "Paris Carbone"], "title": "Holon Streaming: Global Aggregations with Windowed CRDTs", "comment": "10 pages, 9 figures, 2 tables, 2 listings, 2 algorithms", "summary": "Scaling global aggregations is a challenge for exactly-once stream processing\nsystems. Current systems implement these either by computing the aggregation in\na single task instance, or by static aggregation trees, which limits\nscalability and may become a bottleneck. Moreover, the end-to-end latency is\ndetermined by the slowest path in the tree, and failures and reconfiguration\ncause large latency spikes due to the centralized coordination. Towards these\nissues, we present Holon Streaming, an exactly-once stream processing system\nfor global aggregations. Its deterministic programming model uses windowed\nconflict-free replicated data types (Windowed CRDTs), a novel abstraction for\nshared replicated state. Windowed CRDTs make computing global aggregations\nscalable. Furthermore, their guarantees such as determinism and convergence\nenable the design of efficient failure recovery algorithms by decentralized\ncoordination. Our evaluation shows a 5x lower latency and 2x higher throughput\nthan an existing stream processing system on global aggregation workloads, with\nan 11x latency reduction under failure scenarios. The paper demonstrates the\neffectiveness of decentralized coordination with determinism, and the utility\nof Windowed CRDTs for global aggregations.", "AI": {"tldr": "Holon Streaming introduces a novel approach using Windowed CRDTs for scalable global aggregations in stream processing, achieving 5x lower latency and 2x higher throughput than existing systems.", "motivation": "Current stream processing systems face scalability bottlenecks with global aggregations due to single-task computation or static aggregation trees, leading to latency issues and poor failure recovery.", "method": "Uses deterministic programming model with Windowed Conflict-Free Replicated Data Types (Windowed CRDTs) for shared replicated state, enabling decentralized coordination and efficient failure recovery.", "result": "Achieved 5x lower latency and 2x higher throughput compared to existing systems, with 11x latency reduction under failure scenarios.", "conclusion": "Demonstrates effectiveness of decentralized coordination with determinism and utility of Windowed CRDTs for scalable global aggregations in stream processing."}}
