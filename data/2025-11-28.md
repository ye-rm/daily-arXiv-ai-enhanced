<div id=toc></div>

# Table of Contents

- [cs.DC](#cs.DC) [Total: 2]


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [1] [Diagonal Scaling: A Multi-Dimensional Resource Model and Optimization Framework for Distributed Databases](https://arxiv.org/abs/2511.21612)
*Shahir Abdullah,Syed Rohit Zaman*

Main category: cs.DC

TL;DR: The paper introduces a two-dimensional scaling model called the Scaling Plane that combines horizontal scaling (node count) and vertical scaling (per-node resources) for cloud databases, showing that diagonal scaling paths outperform traditional one-dimensional approaches.


<details>
  <summary>Details</summary>
Motivation: Current cloud databases treat scaling as a binary choice between horizontal and vertical scaling, which is limiting because performance, cost, and coordination overhead emerge from the joint interaction of both dimensions. This leads to suboptimal scaling decisions like overreacting to load spikes or underreacting to memory pressure.

Method: Proposes the Scaling Plane model where database configurations are represented as points (H,V) with H as node count and V as resource vector. Introduces DIAGONALSCALE, a discrete local-search algorithm that evaluates horizontal, vertical, and diagonal moves to find optimal configurations minimizing a multi-objective function under SLA constraints.

Result: Diagonal scaling reduces p95 latency by up to 40%, lowers cost-per-query by up to 37%, and reduces rebalancing by 2 to 5 times compared to horizontal-only and vertical-only autoscaling approaches. Experiments on distributed SQL and KV systems validate these improvements.

Conclusion: The results demonstrate the need for multi-dimensional scaling models and provide a foundation for next-generation autoscaling in cloud database systems, showing that optimal scaling trajectories frequently lie along diagonal paths that simultaneously exploit cluster parallelism and per-node improvements.

Abstract: Modern cloud databases present scaling as a binary decision: scale-out by adding nodes or scale-up by increasing per-node resources. This one-dimensional view is limiting because database performance, cost, and coordination overhead emerge from the joint interaction of horizontal elasticity and per-node CPU, memory, network bandwidth, and storage IOPS. As a result, systems often overreact to load spikes, underreact to memory pressure, or oscillate between suboptimal states. We introduce the Scaling Plane, a two-dimensional model in which each distributed database configuration is represented as a point (H, V), with H denoting node count and V a vector of resources. Over this plane, we define smooth approximations of latency, throughput, coordination overhead, and monetary cost, providing a unified view of performance trade-offs. We show analytically and empirically that optimal scaling trajectories frequently lie along diagonal paths: sequences of joint horizontal and vertical adjustments that simultaneously exploit cluster parallelism and per-node improvements. To compute such actions, we propose DIAGONALSCALE, a discrete local-search algorithm that evaluates horizontal, vertical, and diagonal moves in the Scaling Plane and selects the configuration minimizing a multi-objective function subject to SLA constraints. Using synthetic surfaces, microbenchmarks, and experiments on distributed SQL and KV systems, we demonstrate that diagonal scaling reduces p95 latency by up to 40 percent, lowers cost-per-query by up to 37 percent, and reduces rebalancing by 2 to 5 times compared to horizontal-only and vertical-only autoscaling. Our results highlight the need for multi-dimensional scaling models and provide a foundation for next-generation autoscaling in cloud database systems.

</details>


### [2] [AI/ML Model Cards in Edge AI Cyberinfrastructure: towards Agentic AI](https://arxiv.org/abs/2511.21661)
*Beth Plale,Neelesh Karthikeyan,Isuru Gamage,Joe Stubbs,Sachith Withana*

Main category: cs.DC

TL;DR: The paper analyzes the use of Model Context Protocol (MCP) as an interface for dynamic model cards in the ICICLE AI Institute ecosystem, comparing its performance overhead against REST interfaces and evaluating its suitability for enabling active sessions with dynamic model cards.


<details>
  <summary>Details</summary>
Motivation: Traditional AI/ML model cards provide static benchmark evaluations during training but fail to capture how models are actually used throughout their lifecycle. There's a need for dynamic model cards that can track real-world usage patterns over time.

Method: The study implements Patra Model Cards embedded in the ICICLE AI Institute software ecosystem and assesses the Model Context Protocol (MCP) as an interface to the Patra Model Card server. It conducts quantitative analysis of MCP overhead compared to REST interfaces and qualitative evaluation of active sessions enabled by MCP.

Result: Quantitative assessment reveals performance overhead when using MCP compared to REST interfaces. However, MCP enables active sessions that support dynamic model card functionality, addressing the core need for tracking model usage throughout its lifecycle.

Conclusion: While MCP introduces some performance overhead compared to REST interfaces, it provides valuable capabilities for enabling active sessions and dynamic model cards, making it a suitable protocol for tracking model usage patterns over time in real-world applications.

Abstract: AI/ML model cards can contain a benchmarked evaluation of an AI/ML model against intended use but a one time assessment during model training does not get at how and where a model is actually used over its lifetime. Through Patra Model Cards embedded in the ICICLE AI Institute software ecosystem we study model cards as dynamic objects. The study reported here assesses the benefits and tradeoffs of adopting the Model Context Protocol (MCP) as an interface to the Patra Model Card server. Quantitative assessment shows the overhead of MCP as compared to a REST interface. The core question however is of active sessions enabled by MCP; this is a qualitative question of fit and use in the context of dynamic model cards that we address as well.

</details>
