<div id=toc></div>

# Table of Contents

- [cs.AR](#cs.AR) [Total: 1]
- [cs.DC](#cs.DC) [Total: 2]


<div id='cs.AR'></div>

# cs.AR [[Back]](#toc)

### [1] [Sparsity-Aware Streaming SNN Accelerator with Output-Channel Dataflow for Automatic Modulation Classification](https://arxiv.org/abs/2601.02613)
*Kuilian Yang,Li Zhang,Ahmed M. Eltawil,Khaled Nabil Salama*

Main category: cs.AR

TL;DR: A sparsity-aware SNN streaming accelerator for automatic modulation classification achieves 23.5 MS/s throughput (double baseline) with reduced power on FPGA, enabling real-time edge deployment.


<details>
  <summary>Details</summary>
Motivation: The need for efficient spectrum utilization in 5G/6G/IoT systems requires real-time AMC for cognitive radio, but DNNs have high computational/energy demands for edge deployment, while SNNs offer energy efficiency but struggle with throughput-power tradeoffs under hardware constraints.

Method: Proposes a sparsity-aware SNN streaming accelerator using gated one-to-all product (GOAP) algorithm to compute only non-zero input-weight intersections, precomputing extra/empty iterations into dataflow to eliminate dynamic fetches and enable fully pipelined, control-free execution.

Result: FPGA implementation achieves 23.5 MS/s throughput (approximately double baseline) on RadioML 2016 dataset while reducing dynamic power and maintaining comparable classification accuracy.

Conclusion: The SAOCDS accelerator demonstrates strong potential for real-time, low-power deployment in edge cognitive radio systems by integrating advantages of sparsity exploitation and high throughput streaming architectures.

Abstract: The rapid advancement of wireless communication technologies, including 5G, emerging 6G networks, and the large-scale deployment of the Internet of Things (IoT), has intensified the need for efficient spectrum utilization. Automatic modulation classification (AMC) plays a vital role in cognitive radio systems by enabling real-time identification of modulation schemes for dynamic spectrum access and interference mitigation. While deep neural networks (DNNs) offer high classification accuracy, their computational and energy demands pose challenges for real-time edge deployment. Spiking neural networks (SNNs), with their event-driven nature, offer inherent energy efficiency, but achieving both high throughput and low power under constrained hardware resources remains challenging. This work proposes a sparsity-aware SNN streaming accelerator optimized for AMC tasks. Unlike traditional systolic arrays that exploit sparsity but suffer from low throughput, or streaming architectures that achieve high throughput but cannot fully utilize input and weight sparsity, our design integrates both advantages. By leveraging the fixed nature of kernels during inference, we apply the gated one-to-all product (GOAP) algorithm to compute only on non-zero input-weight intersections. Extra or empty iterations are precomputed and embedded into the inference dataflow, eliminating dynamic data fetches and enabling fully pipelined, control-free inter-layer execution. Implemented on an FPGA, our sparsity-aware output-channel dataflow streaming (SAOCDS) accelerator achieves 23.5 MS/s (approximately double the baseline throughput) on the RadioML 2016 dataset, while reducing dynamic power and maintaining comparable classification accuracy. These results demonstrate strong potential for real-time, low-power deployment in edge cognitive radio systems.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [2] [Proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024)](https://arxiv.org/abs/2601.02898)
*Wim Vanderbauwhede,Lauritz Thamsen,Jos√© Cano*

Main category: cs.DC

TL;DR: Proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024)


<details>
  <summary>Details</summary>
Motivation: To address the growing environmental impact of computing systems and promote sustainable computing practices through research and collaboration

Method: Workshop proceedings compiling research papers, presentations, and discussions on low-carbon computing technologies and methodologies

Result: Collection of research contributions covering various aspects of energy-efficient computing, carbon-aware systems, and sustainable IT infrastructure

Conclusion: Establishes a platform for advancing low-carbon computing research and fostering community collaboration toward sustainable computing solutions

Abstract: This is the proceedings of the 1st International Workshop on Low Carbon Computing (LOCO 2024).

</details>


### [3] [Software-Defined Agentic Serving](https://arxiv.org/abs/2601.03197)
*Saurabh Agarwal,Marco Laju,Jayanth Srinivasa,Myungjin Lee,Aditya Akella*

Main category: cs.DC

TL;DR: A new SDN-inspired framework for programmable, system-aware agentic LLM serving that dynamically controls communication based on runtime state.


<details>
  <summary>Details</summary>
Motivation: Existing serving paradigms fail to adapt to dynamic serving conditions in complex multi-agent LLM pipelines, as they statically encode parameters rather than being programmable and system-aware.

Method: Proposes an SDN-inspired agentic serving framework that enables dynamic control of key communication attributes based on runtime state.

Result: The architecture enables serving-efficient and responsive agent systems, paving the way for high-level intent-driven agentic serving.

Conclusion: A new programmable, system-aware serving framework is needed for complex multi-agent LLM pipelines, and the proposed SDN-inspired approach addresses this need by enabling dynamic communication control based on runtime conditions.

Abstract: As multi-agent LLM pipelines grow in complexity, existing serving paradigms fail to adapt to the dynamic serving conditions. We argue that agentic serving systems should be programmable and system-aware, unlike existing serving which statically encode the parameters. In this work, we propose a new SDN-inspired agentic serving framework that helps control the key attributes of communication based on runtime state. This architecture enables serving-efficient, responsive agent systems and paves the way for high-level intent-driven agentic serving.

</details>
