{"id": "2511.03029", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03029", "abs": "https://arxiv.org/abs/2511.03029", "authors": ["Kajol Kulkarni", "Samuel Kemmler", "Anna Schwarz", "Gulcin Gedik", "Yanxiang Chen", "Dimitrios Papageorgiou", "Ioannis Kavroulakis", "Roman Iakymchuk"], "title": "Harvesting energy consumption on European HPC systems: Sharing Experience from the CEEC project", "comment": "10 pages, 11 figures, conference", "summary": "Energy efficiency has emerged as a central challenge for modern\nhigh-performance computing (HPC) systems, where escalating computational\ndemands and architectural complexity have led to significant energy footprints.\nThis paper presents the collective experience of the EuroHPC JU Center of\nExcellence in Exascale CFD (CEEC) in measuring, analyzing, and optimizing\nenergy consumption across major European HPC systems. We briefly review key\nmethodologies and tools for energy measurement as well as define metrics for\nreporting results. Through case studies using representative CFD applications\n(waLBerla, FLEXI/GAL{\\AE}XI, Neko, and NekRS), we evaluate energy-to-solution\nand time-to-solution metrics on diverse architectures, including CPU- and\nGPU-based partitions of LUMI, MareNostrum5, MeluXina, and JUWELS Booster. Our\nresults highlight the advantages of accelerators and mixed-precision techniques\nfor reducing energy consumption while maintaining computational accuracy.\nFinally, we advocate the need to facilitate energy measurements on HPC systems\nin order to raise awareness, teach the community, and take actions toward more\nsustainable exascale computing.", "AI": {"tldr": "This paper presents the EuroHPC JU Center of Excellence in Exascale CFD's experience in measuring and optimizing energy consumption across major European HPC systems using CFD applications, highlighting the benefits of accelerators and mixed-precision techniques for sustainable exascale computing.", "motivation": "Energy efficiency has become a central challenge for modern high-performance computing systems due to escalating computational demands and architectural complexity leading to significant energy footprints.", "method": "The study uses case studies with representative CFD applications (waLBerla, FLEXI/GAL\u00c6XI, Neko, and NekRS) to evaluate energy-to-solution and time-to-solution metrics on diverse CPU- and GPU-based architectures across major European HPC systems including LUMI, MareNostrum5, MeluXina, and JUWELS Booster.", "result": "Results highlight the advantages of accelerators and mixed-precision techniques for reducing energy consumption while maintaining computational accuracy.", "conclusion": "The paper advocates for facilitating energy measurements on HPC systems to raise awareness, educate the community, and take actions toward more sustainable exascale computing."}}
{"id": "2511.03079", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.03079", "abs": "https://arxiv.org/abs/2511.03079", "authors": ["Changhong Li", "Biswajit Basu", "Shreejith Shanker"], "title": "LogicSparse: Enabling Engine-Free Unstructured Sparsity for Quantised Deep-learning Accelerators", "comment": "Accepted by ICFPT 2025", "summary": "FPGAs have been shown to be a promising platform for deploying Quantised\nNeural Networks (QNNs) with high-speed, low-latency, and energy-efficient\ninference. However, the complexity of modern deep-learning models limits the\nperformance on resource-constrained edge devices. While quantisation and\npruning alleviate these challenges, unstructured sparsity remains\nunderexploited due to irregular memory access. This work introduces a framework\nthat embeds unstructured sparsity into dataflow accelerators, eliminating the\nneed for dedicated sparse engines and preserving parallelism. A hardware-aware\npruning strategy is introduced to improve efficiency and design flow further.\nOn LeNet-5, the framework attains 51.6 x compression and 1.23 x throughput\nimprovement using only 5.12% of LUTs, effectively exploiting unstructured\nsparsity for QNN acceleration.", "AI": {"tldr": "A framework that embeds unstructured sparsity into FPGA dataflow accelerators for QNNs, achieving high compression and throughput improvements without dedicated sparse engines.", "motivation": "FPGAs show promise for QNN deployment but face limitations with modern deep-learning models on resource-constrained edge devices. Unstructured sparsity remains underexploited due to irregular memory access patterns.", "method": "Introduces a framework that embeds unstructured sparsity into dataflow accelerators, eliminating dedicated sparse engines while preserving parallelism. Includes a hardware-aware pruning strategy for improved efficiency.", "result": "On LeNet-5, achieves 51.6x compression and 1.23x throughput improvement using only 5.12% of LUTs, effectively exploiting unstructured sparsity.", "conclusion": "The framework successfully enables efficient exploitation of unstructured sparsity for QNN acceleration on FPGAs without requiring specialized sparse hardware."}}
{"id": "2511.03286", "categories": ["cs.DC", "cs.MA", "cs.SE", "cs.SI"], "pdf": "https://arxiv.org/pdf/2511.03286", "abs": "https://arxiv.org/abs/2511.03286", "authors": ["Ehud Shapiro"], "title": "Characterising Global Platforms: Centralised, Decentralised, Federated, and Grassroots", "comment": null, "summary": "Global digital platforms are software systems designed to serve entire\npopulations, with some already serving billions of people. We propose atomic\ntransactions-based multiagent transition systems and protocols as a formal\nframework to study them; introduce essential agents -- minimal sets of agents\nthe removal of which makes communication impossible; and show that the\ncardinality of essential agents partitions all global platforms into four\nclasses:\n  1. Centralised -- one (the server)\n  2. Decentralised -- finite $>1$ (bootstrap nodes)\n  3. Federated -- infinite but not universal (all servers)\n  4. Grassroots -- universal (all agents)\n  Our illustrative formal example is a global social network, for which we\nprovide centralised, decentralised, federated, and grassroots specifications\nvia multiagent atomic transactions, and prove they satisfy basic correctness\nproperties. We discuss informally additional global platforms -- currencies,\n``sharing economy'' apps, AI, and more. While this may be the first\ncharacterisation of centralised, decentralised, and federated global platforms,\ngrassroots platforms have been formally defined previously, but using different\nnotions. Here, we prove that their original definition implies that all agents\nare essential, placing grassroots platforms in a distinct class within the\nbroader formal context that includes all global platforms. This work provides\nthe first mathematical framework for classifying any global platform --\nexisting or imagined -- by providing a multiagent atomic-transactions\nspecification of it and determining the cardinality of the minimal set of\nessential agents in the ensuing multiagent protocol. It thus", "AI": {"tldr": "The paper proposes a formal framework using multiagent atomic transactions to classify global digital platforms into four categories based on the cardinality of essential agents: centralised (1), decentralised (finite >1), federated (infinite but not universal), and grassroots (universal).", "motivation": "To provide a mathematical framework for classifying global digital platforms that serve entire populations, enabling systematic analysis of existing and potential platforms.", "method": "Introduces atomic transactions-based multiagent transition systems and protocols, defines essential agents as minimal sets whose removal prevents communication, and uses cardinality analysis to classify platforms.", "result": "Shows that all global platforms can be partitioned into four classes based on essential agent cardinality, with formal specifications and proofs for a social network example.", "conclusion": "Provides the first comprehensive mathematical framework for classifying any global platform by analyzing multiagent atomic-transaction specifications and essential agent cardinality, placing grassroots platforms in their proper formal context."}}
{"id": "2511.03203", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.03203", "abs": "https://arxiv.org/abs/2511.03203", "authors": ["Deyang Yu", "Chenchen Liu", "Chuanjie Zhang", "Xiao Fang", "Weisheng Zhao"], "title": "An Event-Driven Spiking Compute-In-Memory Macro based on SOT-MRAM", "comment": "5 pages, 7 figures. Under review for ISCAS", "summary": "The application of Magnetic Random-Access Memory (MRAM) in\ncomputing-in-memory (CIM) has gained significant attention. However, existing\ndesigns often suffer from high energy consumption due to their reliance on\ncomplex analog circuits for computation. In this work, we present a Spin-Orbit-\nTorque MRAM(SOT-MRAM)-based CIM macro that employs an event-driven spiking\nprocessing for high energy efficiency. The SOT-MRAM crossbar adopts a hybrid\nseries-parallel cell structure to efficiently support matrix-vector\nmultiplication (MVM). Signal information is (en) decoded as spikes using\nlightweight circuits, eliminating the need for conventional area- and\npowerintensive analog circuits. The SOT-MRAM macro is designed and evaluated in\n28nm technology, and experimental results show that it achieves a peak energy\nefficiency of 243.6 TOPS/W, significantly outperforming existing designs.", "AI": {"tldr": "A novel SOT-MRAM-based computing-in-memory macro using event-driven spiking processing achieves high energy efficiency of 243.6 TOPS/W through hybrid series-parallel cell structure and lightweight spike encoding circuits.", "motivation": "Existing MRAM-based computing-in-memory designs suffer from high energy consumption due to complex analog circuits, creating a need for more energy-efficient solutions.", "method": "Uses SOT-MRAM crossbar with hybrid series-parallel cell structure for matrix-vector multiplication, implements event-driven spiking processing with lightweight circuits for signal encoding/decoding instead of traditional analog circuits.", "result": "Designed and evaluated in 28nm technology, achieves peak energy efficiency of 243.6 TOPS/W, significantly outperforming existing designs.", "conclusion": "The proposed SOT-MRAM-based CIM macro with event-driven spiking processing provides a highly energy-efficient solution for computing-in-memory applications."}}
{"id": "2511.03293", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03293", "abs": "https://arxiv.org/abs/2511.03293", "authors": ["Hai Huang", "Xuhong Qiang", "Weisheng Zhao", "Chenchen Liu"], "title": "UMDAM: A Unified Data Layout and DRAM Address Mapping for Heterogenous NPU-PIM", "comment": "5 pages, 5 figures, under review for IEEE ISCAS", "summary": "Large Language Models (LLMs) are increasingly deployed on edge devices with\nNeural Processing Units (NPUs), yet the decode phase remains memory-intensive,\nlimiting performance. Processing-in-Memory (PIM) offers a promising solution,\nbut co-executing NPU-PIM systems face challenges such as data layout\nmismatches, bandwidth loss, and redundant storage. To address these issues, we\npropose UMDAM, a unified memory-affinity data layout and DRAM address mapping\nscheme tailored for NPU-PIM co-execution. UMDAM employs a column-major,\ntile-based layout and a configurable DRAM mapping strategy to ensure\ncompatibility with NPU computation while maximizing PIM efficiency -- without\nintroducing extra memory overhead or bandwidth loss. Comprehensive evaluations\non OPT models demonstrate that UMDAM reduces time-to-first-token (TTFT) by up\nto 3.0x and time-to-last-token (TTLT) by 2.18x, significantly improving\nend-to-end LLM inference efficiency on edge devices.", "AI": {"tldr": "UMDAM is a unified memory-affinity data layout and DRAM address mapping scheme that optimizes NPU-PIM co-execution for LLM inference on edge devices, achieving up to 3.0x faster TTFT and 2.18x faster TTLT.", "motivation": "LLMs deployed on edge devices with NPUs face memory-intensive decode phases that limit performance, while NPU-PIM co-execution suffers from data layout mismatches, bandwidth loss, and redundant storage issues.", "method": "Proposes UMDAM with column-major, tile-based data layout and configurable DRAM mapping strategy to ensure NPU compatibility while maximizing PIM efficiency without extra memory overhead.", "result": "Evaluations on OPT models show UMDAM reduces time-to-first-token by up to 3.0x and time-to-last-token by 2.18x.", "conclusion": "UMDAM significantly improves end-to-end LLM inference efficiency on edge devices by optimizing NPU-PIM co-execution through unified memory-affinity data layout and address mapping."}}
{"id": "2511.03427", "categories": ["cs.AR"], "pdf": "https://arxiv.org/pdf/2511.03427", "abs": "https://arxiv.org/abs/2511.03427", "authors": ["Florentia Afentaki", "Maha Shatta", "Konstantinos Balaskas", "Georgios Panagopoulos", "Georgios Zervakis", "Mehdi B. Tahoori"], "title": "Design and Optimization of Mixed-Kernel Mixed-Signal SVMs for Flexible Electronics", "comment": "Accepted for publication at IEEE Design Automation & Testing in\n  Europe (DATE 2026)", "summary": "Flexible Electronics (FE) have emerged as a promising alternative to\nsilicon-based technologies, offering on-demand low-cost fabrication,\nconformality, and sustainability. However, their large feature sizes severely\nlimit integration density, imposing strict area and power constraints, thus\nprohibiting the realization of Machine Learning (ML) circuits, which can\nsignificantly enhance the capabilities of relevant near-sensor applications.\nSupport Vector Machines (SVMs) offer high accuracy in such applications at\nrelatively low computational complexity, satisfying FE technologies'\nconstraints. Existing SVM designs rely solely on linear or Radial Basis\nFunction (RBF) kernels, forcing a trade-off between hardware costs and\naccuracy. Linear kernels, implemented digitally, minimize overhead but\nsacrifice performance, while the more accurate RBF kernels are prohibitively\nlarge in digital, and their analog realization contains inherent functional\napproximation. In this work, we propose the first mixed-kernel and mixed-signal\nSVM design in FE, which unifies the advantages of both implementations and\nbalances the cost/accuracy trade-off. To that end, we introduce a\nco-optimization approach that trains our mixed-kernel SVMs and maps binary SVM\nclassifiers to the appropriate kernel (linear/RBF) and domain (digital/analog),\naiming to maximize accuracy whilst reducing the number of costly RBF\nclassifiers. Our designs deliver 7.7% higher accuracy than state-of-the-art\nsingle-kernel linear SVMs, and reduce area and power by 108x and 17x on average\ncompared to digital RBF implementations.", "AI": {"tldr": "Proposes a mixed-kernel, mixed-signal SVM design for flexible electronics that combines linear and RBF kernels across digital and analog domains to optimize the accuracy/hardware cost trade-off.", "motivation": "Flexible electronics face limitations in integration density and power constraints that prevent ML circuit implementation. Existing SVM designs force a trade-off between hardware costs (linear kernels) and accuracy (RBF kernels).", "method": "Co-optimization approach that trains mixed-kernel SVMs and maps binary classifiers to appropriate kernel (linear/RBF) and domain (digital/analog) to maximize accuracy while reducing costly RBF classifiers.", "result": "7.7% higher accuracy than state-of-the-art single-kernel linear SVMs, and 108x area reduction and 17x power reduction compared to digital RBF implementations.", "conclusion": "The mixed-kernel, mixed-signal SVM design successfully balances the cost/accuracy trade-off in flexible electronics, enabling ML circuit implementation with significantly improved performance and reduced hardware overhead."}}
{"id": "2511.03533", "categories": ["cs.DC", "cs.SE"], "pdf": "https://arxiv.org/pdf/2511.03533", "abs": "https://arxiv.org/abs/2511.03533", "authors": ["Nils Japke", "Furat Hamdan", "Diana Baumann", "David Bermbach"], "title": "Investigating the Impact of Isolation on Synchronized Benchmarks", "comment": "Accepted for publication in 2025 IEEE/ACM 18th International\n  Conference on Utility and Cloud Computing", "summary": "Benchmarking in cloud environments suffers from performance variability from\nmulti-tenant resource contention. Duet benchmarking mitigates this by running\ntwo workload versions concurrently on the same VM, exposing them to identical\nexternal interference. However, intra-VM contention between synchronized\nworkloads necessitates additional isolation mechanisms.\n  This work evaluates three such strategies: cgroups and CPU pinning, Docker\ncontainers, and Firecracker MicroVMs. We compare all strategies with an\nunisolated baseline experiment, by running benchmarks with a duet setup\nalongside a noise generator. This noise generator \"steals\" compute resources to\ndegrade performance measurements.\n  All experiments showed different latency distributions while under the\neffects of noise generation, but results show that process isolation generally\nlowered false positives, except for our experiments with Docker containers.\nEven though Docker containers rely internally on cgroups and CPU pinning, they\nwere more susceptible to performance degradation due to noise influence.\nTherefore, we recommend to use process isolation for synchronized workloads,\nwith the exception of Docker containers.", "AI": {"tldr": "This paper evaluates three isolation strategies (cgroups/CPU pinning, Docker containers, Firecracker MicroVMs) for mitigating performance variability in duet benchmarking, finding that process isolation generally reduces false positives except for Docker containers which are more susceptible to noise interference.", "motivation": "Duet benchmarking addresses performance variability in cloud environments from multi-tenant resource contention by running synchronized workloads, but requires additional isolation mechanisms to handle intra-VM contention between the synchronized workloads.", "method": "The researchers evaluated three isolation strategies: cgroups with CPU pinning, Docker containers, and Firecracker MicroVMs. They compared these against an unisolated baseline by running benchmarks in a duet setup alongside a noise generator that intentionally degrades performance measurements.", "result": "All experiments showed different latency distributions under noise generation. Process isolation generally lowered false positives, except for Docker containers which were more susceptible to performance degradation despite internally using cgroups and CPU pinning.", "conclusion": "The paper recommends using process isolation for synchronized workloads in duet benchmarking, with the exception of Docker containers which should be avoided due to their higher susceptibility to performance degradation from noise interference."}}
{"id": "2511.02949", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.02949", "abs": "https://arxiv.org/abs/2511.02949", "authors": ["Zhendong Wang", "Chenyang Meng", "Jun Yang", "Jiayuan Wang", "Yin Li", "Linshan Jiang", "Jin Zhang"], "title": "NF-SecRIS: RIS-Assisted Near-Field Physical Layer Security via Secure Location Modulation", "comment": null, "summary": "The 6G wireless networks impose extremely high requirements on physical layer\nsecure communication. However, the existing solutions usually can only achieve\none-dimensional physical layer security (PLS) in the angle dimension, and\ncannot achieve PLS in the range dimension. In this paper, we propose the\nNF-SecRIS system, the first range-angle-dependent (2D) PLS near-field\ncommunication system based on ultra-large-scale reconfigurable intelligent\nsurface (RIS). We propose the secure location modulation scheme to synthesize\nthe near-field spatial-temporal coding pattern of RIS with extremely low\ncomplexity. It ensures that only legitimate user can receive the raw\nconstellations, while potential eavesdroppers at other ranges or angles can\nonly receive the obfuscated constellations. NF-SecRIS operates without\nrequiring synchronization with either transmitter or receiver. We implement a\nprototype of NF-SecRIS and conduct comprehensive experiments with multiple\nmodulation schemes. The results show that the bit error rate (BER) of\nlegitimate user is below 10^{-4}, while eavesdroppers at other ranges or angles\nsuffer from BER exceeding 40%. It validates the implementation of 2D PLS in\nnear-field communications.", "AI": {"tldr": "The paper proposes NF-SecRIS, the first range-angle-dependent 2D physical layer security system for 6G near-field communications using ultra-large-scale RIS, enabling secure communication where only legitimate users can decode signals while eavesdroppers receive obfuscated constellations.", "motivation": "6G networks require high physical layer security, but existing solutions only provide one-dimensional security in angle dimension and cannot achieve security in range dimension, creating a gap in comprehensive protection.", "method": "Proposed NF-SecRIS system with secure location modulation scheme that synthesizes near-field spatial-temporal coding patterns on RIS with low complexity, operating without synchronization requirements.", "result": "Experimental results show legitimate users achieve BER below 10^{-4}, while eavesdroppers at different ranges or angles suffer from BER exceeding 40%, validating 2D PLS implementation.", "conclusion": "NF-SecRIS successfully implements the first range-angle-dependent 2D physical layer security system for near-field communications, providing comprehensive protection against eavesdroppers in both range and angle dimensions."}}
{"id": "2511.03586", "categories": ["cs.PF", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.03586", "abs": "https://arxiv.org/abs/2511.03586", "authors": ["Andrei Ivanov", "Siyuan Shen", "Gioele Gottardo", "Marcin Chrapek", "Afif Boudaoud", "Timo Schneider", "Luca Benini", "Torsten Hoefler"], "title": "PerfDojo: Automated ML Library Generation for Heterogeneous Architectures", "comment": null, "summary": "The increasing complexity of machine learning models and the proliferation of\ndiverse hardware architectures (CPUs, GPUs, accelerators) make achieving\noptimal performance a significant challenge. Heterogeneity in instruction sets,\nspecialized kernel requirements for different data types and model features\n(e.g., sparsity, quantization), and architecture-specific optimizations\ncomplicate performance tuning. Manual optimization is resource-intensive, while\nexisting automatic approaches often rely on complex hardware-specific\nheuristics and uninterpretable intermediate representations, hindering\nperformance portability. We introduce PerfLLM, a novel automatic optimization\nmethodology leveraging Large Language Models (LLMs) and Reinforcement Learning\n(RL). Central to this is PerfDojo, an environment framing optimization as an RL\ngame using a human-readable, mathematically-inspired code representation that\nguarantees semantic validity through transformations. This allows effective\noptimization without prior hardware knowledge, facilitating both human analysis\nand RL agent training. We demonstrate PerfLLM's ability to achieve significant\nperformance gains across diverse CPU (x86, Arm, RISC-V) and GPU architectures.", "AI": {"tldr": "PerfLLM is an automatic optimization methodology that uses Large Language Models and Reinforcement Learning to optimize machine learning performance across diverse hardware architectures without requiring hardware-specific knowledge.", "motivation": "The increasing complexity of ML models and hardware heterogeneity make manual optimization resource-intensive, while existing automatic approaches rely on complex hardware-specific heuristics that hinder performance portability.", "method": "Uses LLMs and RL with PerfDojo environment that frames optimization as an RL game using human-readable, mathematically-inspired code representation that guarantees semantic validity through transformations.", "result": "Demonstrates significant performance gains across diverse CPU (x86, Arm, RISC-V) and GPU architectures.", "conclusion": "PerfLLM enables effective optimization without prior hardware knowledge, facilitating both human analysis and RL agent training for improved performance portability."}}
{"id": "2511.03609", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03609", "abs": "https://arxiv.org/abs/2511.03609", "authors": ["Cameron Calk", "Emmanuel Godard"], "title": "Stone Duality Proofs for Colorless Distributed Computability Theorems", "comment": null, "summary": "We introduce a new topological encoding by spectral spaces of executions of\n  round-based full-information adversaries, a model of distributed computations\nthat is functorially presented and that\n  contains many message adversaries. We give a characterization of the\nsolvability of colorless tasks against compact adversaries.\n  Message adversaries are distributed\n  models that are known to be very expressive despite being\n  round-based and crash-free. Colorless tasks are\n  an important class of distributed tasks. For a colorless task, the\n  specification does not depend upon the multiplicity of input or\n  output values, like the ubiquitous agreement tasks.\n  Therefore, our result is a significant\n  step toward unifying topological methods in distributed computing.\n  The main insight is to consider global states obtained after finite\nexecutions of a distributed protocol\n  not as abstract\n  simplicial complexes as previously done, but as spectral\n  spaces, considering the Alexandrov topology on the faces poset. Given\n  an adversary $\\mathcal M$ with a set of inputs $\\mathcal I$,\n  we define a limit object $\\Pi^\\infty_\\mathcal M(\\mathcal I)$\n  by projective limit in the category of spectral spaces. We derive a new\ngeneral distributed computability\n  theorem using Stone duality: there exists an algorithm solving a colorless\ntask $(\\mathcal I,\\mathcal O,\\Delta)$\n  against the compact adversary $\\mathcal M$ if and only if there exists a\nspectral\n  map $f:\\Pi^\\infty_\\mathcal M(\\mathcal I)\\longrightarrow\\mathcal O$ compatible\nwith $\\Delta$.\n  From this general characterization are derived many known colorless\ncomputability\n  theorems.\n  Quite surprisingly, colored and uncolored models have the same\n  computability power (they solve the same tasks). Our new proofs give\n  topological reasons for this equivalence, previously known through\n  algorithmic reductions.", "AI": {"tldr": "The paper introduces a new topological encoding using spectral spaces for round-based full-information adversaries in distributed computing, providing a general characterization of solvability for colorless tasks against compact adversaries through Stone duality.", "motivation": "To unify topological methods in distributed computing by developing a functorial presentation that can handle various message adversaries and provide a general computability theorem for colorless tasks.", "method": "Uses spectral spaces and Alexandrov topology on faces posets, defines limit objects via projective limits in the category of spectral spaces, and applies Stone duality to derive computability conditions.", "result": "Establishes that colorless tasks are solvable against compact adversaries if and only if there exists a compatible spectral map between the limit object and output space, revealing that colored and uncolored models have equivalent computability power.", "conclusion": "The spectral space approach provides a unified topological framework for distributed computability, explaining previously known equivalences between colored and uncolored models through topological reasoning rather than algorithmic reductions."}}
{"id": "2511.03119", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.03119", "abs": "https://arxiv.org/abs/2511.03119", "authors": ["Seyed Mohamad Ali Tousi", "G. N. DeSouza"], "title": "QAGT-MLP: An Attention-Based Graph Transformer for Small and Large-Scale Quantum Error Mitigation", "comment": null, "summary": "Noisy quantum devices demand error-mitigation techniques to be accurate yet\nsimple and efficient in terms of number of shots and processing time. Many\nestablished approaches (e.g., extrapolation and quasi-probability cancellation)\nimpose substantial execution or calibration overheads, while existing\nlearning-based methods have difficulty scaling to large and deep circuits. In\nthis research, we introduce QAGT-MLP: an attention-based graph transformer\ntailored for small- and large-scale quantum error mitigation (QEM). QAGT-MLP\nencodes each quantum circuit as a graph whose nodes represent gate instances\nand whose edges capture qubit connectivity and causal adjacency. A dual-path\nattention module extracts features around measured qubits at two scales or\ncontexts: 1) graph-wide global structural context; and 2) fine-grained local\nlightcone context. These learned representations are concatenated with\ncircuit-level descriptor features and the circuit noisy expected values, then\nthey are passed to a lightweight MLP to predict the noise-mitigated values. On\nlarge-scale 100-qubit Trotterized 1D Transverse-Field Ising Models -- TFIM\ncircuits -- the proposed QAGT-MLP outperformed state-of-the-art learning\nbaselines in terms of mean error and error variability, demonstrating strong\nvalidity and applicability in real-world QEM scenarios under matched shot\nbudgets. By using attention to fuse global structures with local lightcone\nneighborhoods, QAGT-MLP achieves high mitigation quality without the increasing\nnoise scaling or resource demand required by classical QEM pipelines, while\nstill offering a scalable and practical path to QEM in modern and future\nquantum workloads.", "AI": {"tldr": "QAGT-MLP is an attention-based graph transformer for quantum error mitigation that encodes circuits as graphs and uses dual-path attention to extract global structural and local lightcone contexts, achieving superior performance on large-scale quantum circuits.", "motivation": "Existing quantum error mitigation techniques impose substantial execution or calibration overheads, while learning-based methods struggle to scale to large and deep circuits, creating a need for efficient and scalable QEM solutions.", "method": "Encode quantum circuits as graphs with nodes representing gates and edges capturing connectivity. Use dual-path attention to extract global structural context and local lightcone context, then combine with circuit descriptors and noisy values in an MLP to predict mitigated values.", "result": "Outperformed state-of-the-art learning baselines on 100-qubit TFIM circuits in terms of mean error and error variability, demonstrating strong validity and applicability under matched shot budgets.", "conclusion": "QAGT-MLP achieves high mitigation quality without increasing noise scaling or resource demands, offering a scalable and practical path to quantum error mitigation for modern quantum workloads."}}
{"id": "2511.03662", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2511.03662", "abs": "https://arxiv.org/abs/2511.03662", "authors": ["Yannis Coutouly", "Emmanuel Godard"], "title": "A General Input-Dependent Colorless Computability Theorem and Applications to Core-Dependent Adversaries", "comment": "OPODIS-25 version", "summary": "Distributed computing tasks can be presented with a triple $(\\I,\\Ou,\\Delta)$.\nThe solvability of a colorless task on the Iterated Immediate Snapshot model\n(IIS) has been characterized by the Colorless Computability Theorem\n\\cite[Th.4.3.1]{HKRbook}. A recent paper~\\cite{CG-24} generalizes this theorem\nfor any message adversaries $\\ma \\subseteq IIS$ by geometric methods. In 2001,\nMost\\'efaoui, Rajsbaum, Raynal, and Roy \\cite{condbased} introduced\n\\emph{condition-based adversaries}. This setting considers a particular\nadversary that will be applied only to a subset of input configurations. In\nthis setting, they studied the $k$-set agreement task with condition-based\n$t$-resilient adversaries and obtained a sufficient condition on the conditions\nthat make $k$-Set Agreement solvable. In this paper we have three\ncontributions:\n  -We generalize the characterization of~\\cite{CG-24} to \\emph{input-dependent}\nadversaries, which means that the adversaries can change depending on the input\nconfiguration.\n  - We show that core-resilient adversaries of $IIS_n$ have the same\ncomputability power as the core-resilient adversaries of $IIS_n$ where crashes\nonly happen at the start.\n  - Using the two previous contributions, we provide a necessary and sufficient\ncharacterization of the condition-based, core-dependent adversaries that can\nsolve $k$-Set Agreement. We also distinguish four settings that may appear when\npresenting a distributed task as $(\\I,\\Ou,\\Delta)$. Finally, in a later\nsection, we present structural properties on the carrier map $\\Delta$. Such\nproperties allow simpler proof, without changing the computability power of the\ntask. Most of the proofs in this article leverage the topological framework\nused in distributed computing by using simple geometric constructions.", "AI": {"tldr": "This paper generalizes distributed computing task solvability characterizations to input-dependent adversaries, shows equivalence between core-resilient adversaries with crashes at different times, and provides necessary/sufficient conditions for solving k-Set Agreement with condition-based adversaries.", "motivation": "To extend existing computability characterizations from fixed message adversaries to input-dependent adversaries, and to better understand the solvability of k-Set Agreement under various adversary models using topological methods.", "method": "Uses geometric and topological framework from distributed computing, generalizing previous characterizations to input-dependent adversaries and analyzing core-resilient adversaries through geometric constructions.", "result": "Proves that core-resilient adversaries have equivalent computability power regardless of crash timing, provides complete characterization for k-Set Agreement solvability with condition-based adversaries, and identifies four distinct settings for distributed task presentation.", "conclusion": "The paper successfully generalizes computability characterizations to input-dependent adversaries, establishes equivalence results for core-resilient adversaries, and provides comprehensive conditions for k-Set Agreement solvability using geometric topological methods."}}
{"id": "2511.03706", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2511.03706", "abs": "https://arxiv.org/abs/2511.03706", "authors": ["Yu-Erh Pan", "Ayesha Siddika Nipu"], "title": "LLM-enhanced Air Quality Monitoring Interface via Model Context Protocol", "comment": "International Symposium on Advanced Electrical and Communication\n  Technologies, ISAECT 2025", "summary": "Air quality monitoring is central to environmental sustainability and public\nhealth, yet traditional systems remain difficult for non-expert users to\ninterpret due to complex visualizations, limited interactivity, and high\ndeployment costs. Recent advances in Large Language Models (LLMs) offer new\nopportunities to make sensor data more accessible, but their tendency to\nproduce hallucinations limits reliability in safety-critical domains. To\naddress these challenges, we present an LLM-enhanced Air Monitoring Interface\n(AMI) that integrates real-time sensor data with a conversational interface via\nthe Model Context Protocol (MCP). Our system grounds LLM outputs in live\nenvironmental data, enabling accurate, context-aware responses while reducing\nhallucination risk. The architecture combines a Django-based backend, a\nresponsive user dashboard, and a secure MCP server that exposes system\nfunctions as discoverable tools, allowing the LLM to act as an active operator\nrather than a passive responder. Expert evaluation demonstrated high factual\naccuracy (4.78), completeness (4.82), and minimal hallucinations (4.84), on a\nscale of 5, supported by inter-rater reliability analysis. These results\nhighlight the potential of combining LLMs with standardized tool protocols to\ncreate reliable, secure, and user-friendly interfaces for real-time\nenvironmental monitoring.", "AI": {"tldr": "An LLM-enhanced Air Monitoring Interface (AMI) that integrates real-time sensor data with conversational interface using Model Context Protocol (MCP) to reduce hallucinations and improve reliability in environmental monitoring.", "motivation": "Traditional air quality monitoring systems are difficult for non-expert users to interpret due to complex visualizations, limited interactivity, and high deployment costs, while LLMs offer accessibility but suffer from hallucinations in safety-critical domains.", "method": "Combines Django-based backend, responsive user dashboard, and secure MCP server that exposes system functions as discoverable tools, allowing LLM to act as active operator grounded in live environmental data.", "result": "Expert evaluation showed high factual accuracy (4.78/5), completeness (4.82/5), and minimal hallucinations (4.84/5), supported by inter-rater reliability analysis.", "conclusion": "Combining LLMs with standardized tool protocols enables reliable, secure, and user-friendly interfaces for real-time environmental monitoring by grounding outputs in live data."}}
